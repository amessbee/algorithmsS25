%\setmainfont{Noteworthy}
%TODO: provide your details here.
\begin{frame}
    \frametitle{About Your Fellows}
    \begin{itemize}
        \item Hi there! We are \textcolor{blue}{\textbf{ Mohid Faisal}  \textcolor{black}{and}\textbf{ Muhammad Wasif}}.
        \item We are Associate Students at ITU.
    \end{itemize}
\end{frame}




\begin{frame}
    \frametitle{Recap: High School Multiplication Algorithm}
    \centering
    \textbf{Time Complexity Analysis:}
    \begin{itemize}
        \item Let \( n \) be the number of digits.
        \item There are \( n^2 \) digit multiplications.
        \item Addition and carry operations take at most \( O(n) \).
        \item Overall, the time complexity is \( O(n^2) \).
    \end{itemize}
    
    \vspace{0.5cm}
    \centering\textbf{\textcolor{red}{Can we do better?}}
\end{frame}

\begin{frame}
    \frametitle{Karatsuba Multiplication Algorithm}
    \vspace{0.3cm} 
    \textbf{Karatsuba Algorithm} $\rightarrow$ the divide and conquer algorithm for Integer Multiplication
    
    \vspace{0.3cm}
    \textbf{Approach:}
    \begin{itemize}
        \item Given two binary numbers: \( X = 0011101010 \), \( Y = 1010000101 \).
        \item Split them into two halves:
        \begin{itemize}
            \item $X_h = \underline{00111}$, $X_l = \underline{01010}$
            \item $Y_h = \underline{10100}$, $Y_l = \underline{00101}$
        \end{itemize}
        \item Reconstruct:
        \begin{itemize}
            \item $X = 2^{n/2} \times \underline{X_h} + \underline{X_l}$
            \item $Y = 2^{n/2} \times \underline{Y_h} + \underline{Y_l}$
        \end{itemize}
        \item Multiply using:
        \begin{equation*}
            X \cdot Y = ( 2^{n/2} \underline{X_h} + \underline{X_l} ) \cdot ( 2^{n/2} \underline{Y_h} + \underline{Y_l} )
        \end{equation*}
        \begin{equation*}
            = 2^n \underline{X_h Y_h} + 2^{n/2} \underline{X_h Y_l} + 2^{n/2} \underline{Y_h X_l} + \underline{X_l Y_l}
        \end{equation*}
        \item Next, we compute the smaller multiplications recursively and then add up the results along with bit shifts to get the final product.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Karatsuba Multiplication Algorithm - Explanation}

    \textbf{Algorithm Overview}  

    Given two numbers \( X \) and \( Y \), the algorithm follows these steps:

    1. If the number of bits is small (base case), multiply directly.
    
    2. Split \( X \) into two halves: higher bits \( X_h \) and lower bits \( X_l \).
    
    3. Split \( Y \) into two halves: higher bits \( Y_h \) and lower bits \( Y_l \).
    
    4. Recursively compute:
       \[
       hh = X_h \times Y_h
       \]
       \[
       hl = X_h \times Y_l
       \]
       \[
       lh = X_l \times Y_h
       \]
       \[
       ll = X_l \times Y_l
       \]

    5. Combine the results using bit shifts:
       \[
       X \times Y = (2^n \times hh) + (2^{n/2} \times (hl + lh)) + ll
       \]

    \textbf{Recurrence Relation:}
    \begin{equation*}
        T(n) = 4T(n/2) + O(n)
    \end{equation*}

    \textbf{By Master Theorem:}
    \begin{equation*}
        T(n) = \Theta(n^2)
    \end{equation*}

\end{frame}



\begin{frame}
    \frametitle{Gauss's Insight}

    Gauss observed that the product of two complex numbers \( (a + bi) \cdot (c + di) \) can be computed using only three multiplications instead of the naive four. Specifically:

    \[
    (a + bi) \cdot (c + di) = (ac - bd) + (ad + bc)i
    \]

    \vspace{0.5cm}

    This can be rewritten using three multiplications:

    \begin{itemize}
        \item Compute \( ac \).
        \item Compute \( bd \).
        \item Compute \( (a + b)(c + d) \).
    \end{itemize}

    \vspace{0.5cm}

    Then, the term \( ad + bc \) can be derived as:

    \[
    ad + bc = (a + b)(c + d) - ac - bd
    \]

    \vspace{0.5cm}

    This reduces the number of multiplications from 4 to 3.
\end{frame}







\begin{frame}
    \frametitle{Optimization of Algorithm}

    \textbf{We can do some algebra to express the multiplication that will require fewer recursive calls and give us a better big-O bound.}

    \vspace{0.5cm}

    \[
    \underline{X} \cdot \underline{Y} = ( 2^{n/2} \underline{X_h} + \underline{X_l} ) \cdot ( 2^{n/2} \underline{Y_h} + \underline{Y_l} )
    \]

    \[
    = 2^n \underline{X_h Y_h} + 2^{n/2} \underline{X_h Y_l} + 2^{n/2} \underline{Y_h X_l} + \underline{X_l Y_l}
    \]

    \vspace{0.5cm}

    \textbf{Note that:}

    \[
    ( \underline{X_h} + \underline{X_l} ) \cdot ( \underline{Y_h} + \underline{Y_l} ) = \underline{X_h Y_h} + ( \underline{X_h Y_l} + \underline{X_l Y_h} ) + \underline{X_l Y_l}
    \]

    \vspace{0.3cm}

    \textbf{Thus:}

    \[
    \underline{X_h Y_l} + \underline{X_l Y_h} = ( \underline{X_h} + \underline{X_l} ) \cdot ( \underline{Y_h} + \underline{Y_l} ) - \underline{X_h Y_h} - \underline{X_l Y_l}
    \]

    \vspace{0.5cm}

    \textbf{Now, instead of four recursive calls, we will make three recursive calls.}

\end{frame}

\begin{frame}
    \frametitle{Optimized Karatsuba Algorithm}

    The optimization reduces the number of recursive calls from 4 to 3 by computing:

    \[
    X \cdot Y = (2^{n/2} X_h + X_l) \cdot (2^{n/2} Y_h + Y_l)
    \]

    Expanding and rearranging using Gauss's trick:

    \[
    X \cdot Y = 2^n X_h Y_h + 2^{n/2} (X_h Y_l + X_l Y_h) + X_l Y_l
    \]

    Instead of computing \( X_h Y_l \) and \( X_l Y_h \) separately, we compute:

    \[
    P = (X_h + X_l) \cdot (Y_h + Y_l)
    \]

    Then, we derive:

    \[
    X_h Y_l + X_l Y_h = P - X_h Y_h - X_l Y_l
    \]

    \vspace{0.1cm}
    \textbf{Optimized Recurrence Relation:}
    \[
        T(n) = 3T(n/2) + O(n)
    \]

    \textbf{By Master Theorem:}
    \[
        T(n) = \Theta(n^{\log_2 3})
    \]

\end{frame}


\begin{frame}
    \frametitle{Karatsuba Multiplication - Visual Representation}
    \centering
    \begin{tikzpicture}[scale=0.8, every node/.style={font=\small}]
        % Define positions
        \def\xstart{2}
        \def\ystart{0}
        \def\width{1.2}  % Box width
        \def\height{0.8} % Box height
        \def\gap{0.2}    % Gap between splits

        % Binary numbers
        \node[left] at (\xstart-1, \ystart+0.5*\height) {\textbf{X} $\rightarrow$};
        \node[left] at (\xstart-1, \ystart-1.5*\height) {\textbf{Y} $\rightarrow$};

        % X number
        \foreach \i [count=\j] in {1,0,1,1,0,1,0,0} {
            \draw[thick] (\xstart+\j*\width, \ystart) rectangle ++(\width, \height);
            \node at (\xstart+\j*\width+0.5*\width, \ystart+0.5*\height) {\i};
        }

        % Y number (below X)
        \foreach \i [count=\j] in {1,1,0,1,1,0,0,1} {
            \draw[thick] (\xstart+\j*\width, \ystart-2*\height) rectangle ++(\width, \height);
            \node at (\xstart+\j*\width+0.5*\width, \ystart-2*\height+0.5*\height) {\i};
        }

        % Adjusted partitioning exactly at the 4th block boundary
        \draw[dashed, green, thick] (\xstart+5*\width, \ystart+0.1) -- (\xstart+5*\width, \ystart+\height-0.1);
        \draw[dashed, green, thick] (\xstart+5*\width, \ystart-1.9*\height) -- (\xstart+5*\width, \ystart-2*\height+\height-0.1);

        % Labels for high and low parts
        \node[green, above] at (\xstart+3*\width, \ystart+\height+0.3) {$X_h$};
        \node[green, above] at (\xstart+7*\width, \ystart+\height+0.3) {$X_l$};

        \node[green, above] at (\xstart+3*\width, \ystart-1*\height) {$Y_h$};
        \node[green, above] at (\xstart+7*\width, \ystart-1*\height) {$Y_l$};

        % Recursive Calls
        \node[below] at (\xstart+4*\width, \ystart-3*\height) {\textbf{Recursive Multiplications:}};
        \node[below] at (\xstart+4*\width, \ystart-4*\height) {$hh = X_h \times Y_h$};
        \node[below] at (\xstart+4*\width, \ystart-5*\height) {$ll = X_l \times Y_l$};
        \node[below] at (\xstart+4*\width, \ystart-6*\height) {$(X_h+X_l) \times (Y_h+Y_l) - hh - ll$};

        % Final result combination
        \node[below] at (\xstart+4*\width, \ystart-7*\height) {\textbf{Final Result:}};
        \node[below] at (\xstart+4*\width, \ystart-8*\height) {$2^n \times hh + 2^{n/2} \times (hl+lh) + ll$};
    \end{tikzpicture}
\end{frame}

\begin{frame}{Time Complexity Comparison}

  \begin{columns}
      % Left column for legend (key)
      \column{0.3\textwidth}
      \textbf{Multiplication Algorithms:}
      \begin{itemize}
          \item \textcolor{red}{$O(n^2)$} - High School Method
          \item \textcolor{green}{$O(n^{1.585})$} - Karatsuba Algorithm
      \end{itemize}

      % Right column for graph
      \column{0.7\textwidth}
      \begin{tikzpicture}
          \begin{axis}[
              xlabel={$n$ (Input Size)},
              ylabel={Computational Cost},
              xmin=5, xmax=30,
              ymin=0, ymax=900,
              grid=major
          ]
          
          % Red Curve (O(n^2)) - High School Algorithm
          \addplot[red, mark=*, dashed] coordinates {
              (5, 25) (10, 100) (15, 225) (20, 400) (25, 625) (30, 900)
          };
          
          % Purple Curve (O(n^1.585)) - Karatsuba Algorithm
          \addplot[green, mark=*, solid] coordinates {
              (5, 10) (10, 50) (15, 150) (20, 300) (25, 450) (30, 700)
          };

          \end{axis}
      \end{tikzpicture}
  \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Strassen's Matrix Multiplication}

    \textbf
    Strassenâ€™s algorithm is a \textbf{divide-and-conquer} approach for matrix multiplication that is asymptotically faster than the conventional method. It reduces the number of multiplications required, improving efficiency.

    \vspace{0.5cm}
    \textbf{Standard Matrix Multiplication:}  
    For two \( n \times n \) matrices \( A \) and \( B \), the traditional matrix multiplication requires:
    
    \begin{itemize}
        \item \( O(n^3) \) scalar multiplications.
        \item \( O(n^3) \) scalar additions.
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{Strassenâ€™s Approach}

    \textbf  
    Strassenâ€™s algorithm breaks down the multiplication process using \textbf{divide and conquer} and reduces the number of scalar multiplications.

    \vspace{0.5cm}
    \textbf{Step 1: Divide the Matrices}  
    For two \( n \times n \) matrices \( A \) and \( B \), split each into four \( \frac{n}{2} \times \frac{n}{2} \) submatrices:

    \[
    A =
    \begin{bmatrix}
        \textcolor{red}{A_{11}} & \textcolor{red}{A_{12}} \\
        \textcolor{red}{A_{21}} & \textcolor{red}{A_{22}}
    \end{bmatrix}
    , \quad
    B =
    \begin{bmatrix}
        \textcolor{red}{B_{11}} & \textcolor{red}{B_{12}} \\
        \textcolor{red}{B_{21}} & \textcolor{red}{B_{22}}
    \end{bmatrix}
    \]

    where each \( \textcolor{red}{A_{ij}} \) and \( \textcolor{red}{B_{ij}} \) is of size \( \frac{n}{2} \times \frac{n}{2} \).

    
\end{frame}

\begin{frame}
    \frametitle{Strassenâ€™s Algorithm: Recursive Multiplications}

    \textbf{Step 2: Compute 7 Recursive Multiplications}  
    Instead of directly computing the 8 matrix products, Strassen defined 7 intermediate matrix products:

   \[
    M_1 = (\textcolor{red}{A_{11}} + \textcolor{red}{A_{22}}) (\textcolor{red}{B_{11}} + \textcolor{red}{B_{22}})
\]
\[
    M_2 = (\textcolor{red}{A_{21}} + \textcolor{red}{A_{22}}) \textcolor{red}{B_{11}}
\]
\[
    M_3 = \textcolor{red}{A_{11}} (\textcolor{red}{B_{12}} - \textcolor{red}{B_{22}})
\]
\[
    M_4 = \textcolor{red}{A_{22}} (\textcolor{red}{B_{21}} - \textcolor{red}{B_{11}})
\]
\[
    M_5 = (\textcolor{red}{A_{11}} + \textcolor{red}{A_{12}}) \textcolor{red}{B_{22}}
\]
\[
    M_6 = (\textcolor{red}{A_{21}} - \textcolor{red}{A_{11}}) (\textcolor{red}{B_{11}} + \textcolor{red}{B_{12}})
\]
\[
    M_7 = (\textcolor{red}{A_{12}} - \textcolor{red}{A_{22}}) (\textcolor{red}{B_{21}} + \textcolor{red}{B_{22}})
\]


\end{frame}

\begin{frame}
    \frametitle{Strassenâ€™s Algorithm: Compute Result Matrix}

    \textbf{Step 3: Compute the Result Matrix}  
    Using the intermediate results, we compute the submatrices of \( C \):

    \[
    \textcolor{red}{C_{11}} = M_1 + M_4 - M_5 + M_7
\]
\[
    \textcolor{red}{C_{12}} = M_3 + M_5
\]
\[
    \textcolor{red}{C_{21}} = M_2 + M_4
\]
\[
    \textcolor{red}{C_{22}} = M_1 - M_2 + M_3 + M_6
\]


\end{frame}

\begin{frame}
    \frametitle{Time Complexity Analysis}

    Strassen's method reduces the number of multiplications from 8 to 7, but it increases the number of additions and subtractions.

    \textbf{Recurrence Relation:}
    \[
    T(n) = 7T(n/2) + O(n^2)
    \]

    \textbf{Solving using the Master Theorem:}
    \[
    T(n) = O(n^{\log_2 7}) \approx O(n^{2.81})
    \]

    This is faster than the standard matrix multiplication complexity of \( O(n^3) \).
\end{frame}


\begin{frame}
  \frametitle{The Secretary Problem: Background and Rules}
  
  During WWII, new treatments were often tested on human subjects to determine their effectiveness. Researchers grappled with a critical question: when was the optimal point to stop testing and adopt a treatment? This dilemma inspired the Secretary Problem (or Optimal Stopping Problem) in computer scienceâ€”deciding the best moment to stop searching among sequentially presented options to maximize the chance of selecting the best one.
  \begin{block}{Rules}
      \begin{itemize}
        \item Candidates are interviewed one at a time in a random order.
        \item You must decide immediately after each interview.
        \item Once a candidate is rejected, you cannot go back and hire them.
        \item Only one candidate can be selected.
        \item The objective is to choose the best candidate overall.
      \end{itemize}
    \end{block}  
\end{frame}



  \begin{frame}
      \frametitle{The Secretary Problem: Algorithm}
      \begin{columns}[t]
        \column{0.5\textwidth}
          \begin{block}{Algorithm}
            \begin{enumerate}
              \item Determine the total number of candidates (n).
              \item Interview the first $k$ candidates and record the best candidate seen ($x$).
              \item For each candidate from $k+1$ to $n$, if a candidate is better than $x$, hire them immediately and stop.
              \item If no candidate after the observation phase is better, select the last candidate.
            \end{enumerate}
          \end{block}
        \column{0.5\textwidth}
          \centering
          \begin{tikzpicture}[scale=0.5]
            % Parameters for visualization
            \def\n{8}         % Total number of candidates (example: 8)
            \def\width{1}     % Width of each rectangle
            \def\height{1.2}  % Height of each rectangle
            \def\gap{0.3}     % Gap between rectangles
            
            % Draw the array of candidate rectangles
            \foreach \i in {1,...,\n} {
              \draw[thick] ({(\i-1)*(\width+\gap)},0) rectangle ++(\width, \height);
              \node at ({(\i-1)*(\width+\gap)+0.5*\width}, {0.5*\height}) {\i};
            }
            
            % Mark the observation phase boundary at candidate k (assume k=3)
            \def\k{4}
            \draw[red, dashed, thick] ({\k*(\width+\gap)-\gap/2}, -0.3) -- ({\k*(\width+\gap)-\gap/2}, \height+0.9);
            \node[red] at ({\k*(\width+\gap)-\gap/2}, -1) {$k$};
    
            % Highlight the best candidate (x) among the first k (assume candidate 2 is best)
            \def\x{2}
            \draw[blue, thick] ({(\x-1)*(\width+\gap)}, 0) rectangle ++(\width, \height);
            \node[blue] at ({(\x-1)*(\width+\gap)+0.5*\width}, -0.5) {$x$};
            \node[blue] at ({(\x-1)*(\width*0.5+\gap)+0.5*\width}, -1.5) {Best Candidate};

            \def\x{6}
            \draw[green, thick] ({(\x-1)*(\width+\gap)}, 0) rectangle ++(\width, \height);
            \node[green] at ({(\x-1)*(\width+\gap)+0.5*\width}, -0.5) {$i$};

          \end{tikzpicture}
          \vspace*{3cm} % Adjust the space as needed to push the text toward the bottom
          {\color{red}\textbf{}}
          {\color{red}\textbf{}}
          {\color{red}\textbf{}}
          {\color{red}\textbf{Let's analyze! But before thatâ€¦}}
          {\color{red}\textbf{Some Background of Probability.}}
      \end{columns}
    \end{frame}
    
    \begin{frame}
      \frametitle{Probability Background}
      \begin{columns}[T]
        \column{0.6\textwidth}
           \begin{block}{Uniform Probability: Definition}
    In a uniform probability modelâ€”where every outcome is equally likelyâ€”the probability of an event \(E\) is given by:
    \[
      P(E) = \frac{|E|}{|S|},
    \]
    where:
    \begin{itemize}
      \item \(|S|\) is the total number of outcomes (sample space).
      \item \(|E|\) is the number of favorable outcomes.
    \end{itemize}
    Consequently, for any outcome \(x\) in \(S\),
    \[
      P(x) = \frac{1}{|S|}.
    \]
  \end{block}
          
        \column{0.4\textwidth}
          \centering
          \begin{tikzpicture}[scale=1]
            % Draw the sample space as a circle
            \draw[thick] (0,0) circle (1.5cm);
            \node at (0,2.3) {Sample Space \(S\)};
            % Draw event E as an inner circle
            \draw[fill=blue!20, thick] (0,0) circle (0.6cm);
            \node at (0,0) {\(E\)};
            % Add an annotation arrow with text indicating E âŠ‚ S
            \draw[->, red, thick] (0.3,0.3) -- (1.7,1.7);
            \node[red, right] at (1.7,1.7) {\(E \subset S\)};
          \end{tikzpicture}
      \end{columns}
    \end{frame}
    
      \begin{frame}
          \frametitle{Probability Background}
        
      \begin{block}{Conditional Probability}
        The probability of an event \(E\) given that event \(F\) occurs [P(F)=1] is
        \[
          P(E \mid F) = \frac{P(E \cap F)}{P(F)}, \quad P(F) > 0.
        \] 
        \end{block}            
        \begin{block}{Independent Events} 
        Events \(E\) and \(F\) are independent if the occurrence of one does not depend on the other.
        \[
          \text{Since E and F are independent: }
          P(E) = P(E \mid F)
        \]
        and similarly
        \[
          P(F) = P(F \mid E)
        \]
      \end{block}
    
    \end{frame}

    \begin{frame}
      \frametitle{Probability of Optimal Hire}
      \centering
      \[
P(\text{OH}) = \text{we hire the best candidate}
\]
      \begin{tikzpicture}[scale=0.5, every node/.style={font=\small}]
        % Parameters for visualization
        \def\n{13}         % Total number of candidates (example: 8)
        \def\width{1}     % Width of each rectangle
        \def\height{1.2}  % Height of each rectangle
        \def\gap{0.3}     % Gap between rectangles
        
        % Draw the array of candidate rectangles
        \foreach \i in {1,...,\n} {
          \draw[thick] ({(\i-1)*(\width+\gap)},0) rectangle ++(\width, \height);
          \node at ({(\i-1)*(\width+\gap)+0.5*\width}, {0.5*\height}) {\i};
        }
        
        % Mark the observation phase boundary at candidate k (assume k=4)
        \def\k{4}
        \draw[red, dashed, thick] ({\k*(\width+\gap)-\gap/2}, -0.3) -- ({\k*(\width+\gap)-\gap/2}, \height+0.9);
        \node[red] at ({\k*(\width+\gap)-\gap/2}, -1) {$k$};
        
        % Highlight the best candidate (x) among the first k (assume candidate 2 is best)
        \def\x{2}
        \draw[blue, thick] ({(\x-1)*(\width+\gap)}, 0) rectangle ++(\width, \height);
        \node[blue] at ({(\x-1)*(\width+\gap)+0.5*\width}, -0.5) {$x$};
        \node[blue] at ({(\x-1)*(\width+\gap)+0.5*\width}, -1.5) {Best Candidate};
        
        % Highlight candidate i in green (assume candidate 6)
        \def\iCandidate{9}
        \draw[green, thick] ({(\iCandidate-1)*(\width+\gap)}, 0) rectangle ++(\width, \height);
        \node[green] at ({(\iCandidate-1)*(\width+\gap)+0.5*\width}, -0.5) {$i$};
        
        % Draw region K as a double-headed arrow (red) below the array
\draw[<->, red, thick] (-0.1, -2.4) -- ({\k*(\width+\gap)-\gap+0.1}, -2.4);
\node[red] at ({(-0.1 + (\k*(\width+\gap)-\gap+0.1))/2}, -3.2) {\textbf{k ( Sample Size from 1 to K )}};

% Draw region I as a double-headed arrow (blue) below the array, shifted down to create space
\draw[<->, blue, thick] (-0.1, -3.8) -- ({\iCandidate*(\width+\gap)-\gap+0.1}, -3.8);
\node[blue] at ({((\k*(\width+\gap)-\gap) + (\iCandidate*(\width+\gap)-\gap+0.1))/2}, -4.5) {\textbf{i ( Sample Size from 1 to i )}};

      \end{tikzpicture}
      \[
        P(OH) = \sum_{i=k+1}^{n} \left( P(i\ \text{is best and we hire }i)   \right)
      \]

     \begin{itemize}
      \item Why use k+1 instead of 1?
     \end{itemize} 
     \[
P(\text{OH}) = 0, \text{Since we never hire the first k candidates}
\]


    \end{frame}

    \begin{frame}
      \frametitle{Probability of Optimal Hire}
      \centering
      \[
        P(OH_i) = i\ \text{is best and we hire }i
        \]
        \begin{itemize}
          \item \(B_i\): \(i\)-th candidate is the best
          \item \(O_i\): none of the applicants in \(\{k+1 \ldots i-1\}\) are picked
        \end{itemize}
      
        \[
          OH_i = B_i \;\land\; O_i
        \]
\[
P(\text{OH}_i)
= P\bigl(B_i \wedge O_i\bigr)
\]
\[
P(\text{OH}_i)
= P\bigl(B_i\bigr) \times \Pr\bigl(O_i \mid B_i\bigr)
\]
\begin{itemize}
\item Since \(B_i\) and \(O_i\) are independent:
\end{itemize}

\[
P(\text{OH}_i)
= P\bigl(B_i\bigr) \times P\bigl(O_i\bigr)
\]
    \end{frame}
\begin{frame}
\frametitle{Probability of Optimal Hire}
\centering
\[
P(B_i)= \frac{1}{n},      \text{     [Uniform Probability]}
\]
\[
  P(O_i)= \frac{k-1}{i-1}
  \]
  \[
P(\text{OH}_i)
= P\bigl(B_i\bigr) \times P\bigl(O_i\bigr)
\]
\[
P(\text{OH}_i)
= \frac{1}{n} \times \frac{k-1}{i-1}
\]
\[
P(\text{OH}) = \sum_{i=k+1}^{n} \left( \frac{1}{n} \times \frac{k-1}{i-1}   \right)
\]


\end{frame}
    \begin{frame}
      \frametitle{Maximum Probability of Optimal Hire}
      \begin{block}{Class Discussion}
        \begin{itemize}
          \item \textbf{Professor:} What is the best value of \(k\) to maximize the Probability of Optimal Hire?
          \item \textbf{Sharib:} \(k = \frac{n}{3}\).
          \item \textbf{Other students:} (suggested different values)
          \item \textbf{Professor:} We will find that in the next class. Time's up!
        \end{itemize}
      \end{block}
    \end{frame}
    
    